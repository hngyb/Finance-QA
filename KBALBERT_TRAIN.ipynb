{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"KBALBERT_TRAIN.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a_q-JmPAv8i","executionInfo":{"status":"ok","timestamp":1624890142410,"user_tz":-540,"elapsed":20298,"user":{"displayName":"김홍엽","photoUrl":"","userId":"06217825977108674510"}},"outputId":"9375e188-2d64-47d3-feb3-c777775bca6f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOfkhSWOA4WS","executionInfo":{"status":"ok","timestamp":1624890149557,"user_tz":-540,"elapsed":7154,"user":{"displayName":"김홍엽","photoUrl":"","userId":"06217825977108674510"}},"outputId":"208002c9-2517-4193-9e0a-c0720d756601"},"source":["!pip install torch transformers datasets"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/d5/c6c23ad75491467a9a84e526ef2364e523d45e2b0fae28a7cbe8689e7e84/transformers-4.8.1-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 5.7MB/s \n","\u001b[?25hCollecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/a2/d4e1024c891506e1cee8f9d719d20831bac31cb5b7416983c4d2f65a6287/datasets-1.8.0-py3-none-any.whl (237kB)\n","\u001b[K     |████████████████████████████████| 245kB 51.0MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 64.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 54.1MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 60.0MB/s \n","\u001b[?25hCollecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3a/666e63625a19883ae8e1674099e631f9737bd5478c4790e5ad49c5ac5261/fsspec-2021.6.1-py3-none-any.whl (115kB)\n","\u001b[K     |████████████████████████████████| 122kB 71.9MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers, xxhash, fsspec, datasets\n","Successfully installed datasets-1.8.0 fsspec-2021.6.1 huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.1 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DAP10_txA5bv"},"source":["import json\n","from pathlib import Path\n","from tqdm import tqdm\n","from transformers.data.processors.squad import SquadExample, squad_convert_examples_to_features\n","\n","def create_examples(input_data, set_type):\n","    is_training = set_type == \"train\"\n","    examples = []\n","\n","    for entry in tqdm(input_data):\n","        title = entry[\"title\"]\n","        for paragraph in entry[\"paragraphs\"]:\n","            context_text = paragraph[\"context\"]\n","            for qa in paragraph[\"qas\"]:\n","                qas_id = qa[\"id\"]\n","                question_text = qa[\"question\"]\n","                start_position_character = None\n","                answer_text = None\n","                answers = []\n","\n","                is_impossible = qa.get(\"is_impossible\", False)\n","                if not is_impossible:\n","                    if is_training:\n","                        answer = qa[\"answers\"][0]\n","                        answer_text = answer[\"text\"]\n","                        start_position_character = answer[\"answer_start\"]\n","                    else:\n","                        answers = qa[\"answers\"]\n","\n","                example = SquadExample(\n","                    qas_id=qas_id,\n","                    question_text=question_text,\n","                    context_text=context_text,\n","                    answer_text=answer_text,\n","                    start_position_character=start_position_character,\n","                    title=title,\n","                    is_impossible=is_impossible,\n","                    answers=answers,\n","                )\n","                examples.append(example)\n","    return examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVEWB6OiBBRo"},"source":["def get_train_examples(data_dir, filename):\n","    if data_dir is None:\n","        data_dir = \"\"\n","    if filename is None:\n","        filename = \"ko_nia_normal_squad_all.json\"\n","\n","    path = data_dir + \"/\" + filename\n","    path = Path(path)\n","        \n","    with open(path, 'rb') as f:\n","      input_data = json.load(f)[\"data\"]\n","\n","    return create_examples(input_data, \"train\")\n","\n","def get_dev_examples(data_dir, filename):\n","    if data_dir is None:\n","        data_dir = \"\"\n","    if filename is None:\n","        filename = \"ko_nia_normal_squad_all.json\"\n","\n","    path = data_dir + \"/\" + filename\n","    path = Path(path)\n","        \n","    with open(path, 'rb') as f:\n","      input_data = json.load(f)[\"data\"]\n","\n","    return create_examples(input_data, \"dev\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3A5DHjvBBpJ","executionInfo":{"status":"ok","timestamp":1624890204867,"user_tz":-540,"elapsed":28509,"user":{"displayName":"김홍엽","photoUrl":"","userId":"06217825977108674510"}},"outputId":"49247b39-97fb-4f1a-d426-4182bb128219"},"source":["train_examples = get_train_examples(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP_QA/QA_Dataset/data3\", \"train.json\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 9882/9882 [00:23<00:00, 413.55it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxohE_k_BedO","executionInfo":{"status":"ok","timestamp":1624890204868,"user_tz":-540,"elapsed":15,"user":{"displayName":"김홍엽","photoUrl":"","userId":"06217825977108674510"}},"outputId":"430b1161-f2fd-43b3-f906-d05c73480974"},"source":["cd /content/gdrive/MyDrive/Colab_Notebooks/NLP_QA/KB-ALBERT-KO/kb-albert-char"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab_Notebooks/NLP_QA/KB-ALBERT-KO/kb-albert-char\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ZTMHLKNBonZ"},"source":["from transformers import AlbertForQuestionAnswering, TrainingArguments, Trainer\n","from tokenization_kbalbert import KbAlbertCharTokenizer\n","\n","MODEL_PATH = \"./model\"\n","tokenizer = KbAlbertCharTokenizer.from_pretrained(MODEL_PATH)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzrGZhixBx8s","executionInfo":{"status":"ok","timestamp":1624891756553,"user_tz":-540,"elapsed":1548265,"user":{"displayName":"김홍엽","photoUrl":"","userId":"06217825977108674510"}},"outputId":"85987b15-2e91-42eb-fa43-0c24129a792b"},"source":["max_length = 384\n","doc_stride = 128\n","max_query_length = 64\n","\n","train_features, train_dataset = squad_convert_examples_to_features(\n","    examples=train_examples,\n","    tokenizer=tokenizer,\n","    max_seq_length=max_length,\n","    doc_stride=doc_stride,\n","    max_query_length=max_query_length,\n","    is_training=True,\n","    return_dataset=\"pt\",\n",")\n","\n","# valid_features, valid_dataset = squad_convert_examples_to_features(\n","#     examples=train_examples,\n","#     tokenizer=tokenizer,\n","#     max_seq_length=max_length,\n","#     doc_stride=doc_stride,\n","#     max_query_length=max_query_length,\n","#     is_training=True,\n","#     return_dataset=\"pt\",\n","# )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["convert squad examples to features: 100%|██████████| 50023/50023 [25:41<00:00, 32.45it/s]\n","add example index and unique id: 100%|██████████| 50023/50023 [00:00<00:00, 317492.87it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzoStHzMB0uY","collapsed":true,"outputId":"af44663f-17dd-4b6f-b921-c2cf2e559301"},"source":["import time\n","import logging\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler\n","from torch.utils.tensorboard import SummaryWriter\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from tqdm import trange\n","logger = logging.getLogger(__name__)\n","\n","train_batch_size = 16\n","gradient_accumulation_steps = 1\n","num_train_epochs = 3.0\n","max_grad_norm = 1.0\n","\n","tb_writer = SummaryWriter()\n","\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=train_batch_size)\n","model = AlbertForQuestionAnswering.from_pretrained(MODEL_PATH)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)\n","t_total = len(train_dataloader) //  gradient_accumulation_steps * num_train_epochs\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=0, num_training_steps=t_total\n",")\n","\n","logger.info(\"***** Running training *****\")\n","logger.info(\"  Num examples = %d\", len(train_dataset))\n","logger.info(\"  Num Epochs = %d\", num_train_epochs)\n","logger.info(\"  Gradient Accumulation steps = %d\", gradient_accumulation_steps)\n","logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","global_step = 1\n","epochs_trained = 0\n","steps_trained_in_current_epoch = 0\n","tr_loss, logging_loss = 0.0, 0.0\n","model.zero_grad()\n","\n","train_iterator = trange(epochs_trained, int(num_train_epochs), desc=\"Epoch\")\n","\n","for _ in train_iterator:\n","  # epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n","  for step, batch in enumerate(train_dataloader):\n","\n","    model.train()\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    inputs = {\n","      \"input_ids\": batch[0],\n","      \"attention_mask\": batch[1],\n","      \"token_type_ids\": batch[2],\n","      \"start_positions\": batch[3],\n","      \"end_positions\": batch[4],\n","    }\n","\n","    outputs = model(**inputs)\n","\n","    loss = outputs[0]\n","    loss.backward()\n","\n","    tr_loss += loss.item()\n","    if (step + 1) % gradient_accumulation_steps == 0:\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","\n","      optimizer.step()\n","      scheduler.step()\n","      model.zero_grad()\n","      global_step += 1\n","\n","    tb_writer.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at ./model were not used when initializing AlbertForQuestionAnswering: ['predictions.dense.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'sop_classifier.classifier.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight']\n","- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at ./model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jd9PWXMVEdQf"},"source":["model.save_pretrained(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP_QA/KBALBERT_MODEL_V2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sMK7JTXYSdI"},"source":["tokenizer.save_pretrained(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP_QA/KBALBERT_MODEL_V2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stn8EyeeYxc_"},"source":[""],"execution_count":null,"outputs":[]}]}